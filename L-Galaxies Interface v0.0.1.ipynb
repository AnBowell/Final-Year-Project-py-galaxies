{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define modules needed and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputFiles          : {'graphFile': '/lustre/scratch/astro/ab898/FYP/Input Data/mega_graph_mini.hdf5'}\n",
      "outputFiles         : {'haloFile': '/lustre/scratch/astro/ab898/FYP/Output Data/SMT13HaloOutput.hdf5', 'galaxyFile': '/lustre/scratch/astro/ab898/FYP/Output Data/SMT13GalaxyOutput.hdf5'}\n",
      "cosmology           : {'OmegaM': {'Description': 'Matter density parameter', 'Value': 0.3, 'Units': 'None'}, 'fBaryon': {'Description': 'Baryon fraction', 'Value': 0.155, 'Units': 'None'}}\n",
      "modelSwitches       : {'HOD': {'Description': 'Halo occupation description for stars (as primitive test)', 'Value': True}}\n",
      "performance         : {'io_nRec': {'Description': 'Size of HDF5 io buffer (number of records)', 'Value': 1000}}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" L-galaxies python interface.\n",
    "\n",
    "This notebook reads in halo merger graphs, performs simple operations, \n",
    "outputting the results to and HDF file.\n",
    "\n",
    "\n",
    "Attributes \n",
    "----------\n",
    "n_halo_max : float\n",
    "    Development limiter.\n",
    "debug_flag : bool\n",
    "    When debugging, set to true in order to print out useful infomation.\n",
    "verbosity : int\n",
    "    0 prints major program steps, 1-2 are major and minor counters, 3 - Debugging diags.\n",
    "file_parameters : str\n",
    "    Filepath to input parameters yml file.\n",
    "display_parameters : bool\n",
    "    Whether or not to display the contents of the yml file.\n",
    "parameters : '(dict of str: (dict of str: str))'\n",
    "    Input parameters from yml file. Contains input/output filepaths, constants etc.\n",
    "f_baryon : float\n",
    "    Baryon fraction for halos.\n",
    "io_nRec : int\n",
    "    Size of HDF5 io buffer.\n",
    "dtype_halo : dtype\n",
    "    Numpy dtype describing the types of the different class attributes.\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "import yaml\n",
    "\n",
    "\n",
    "n_halo_max = np.inf\n",
    "\n",
    "\n",
    "debug_flag = False\n",
    "\n",
    "\n",
    "verbosity = 1 \n",
    "\n",
    "file_parameters='Input_Params/input_params.yml'\n",
    "\n",
    "display_parameters = True\n",
    "\n",
    "parameters = yaml.load(open(file_parameters),Loader=yaml.Loader)\n",
    "\n",
    "if display_parameters:\n",
    "    for item in parameters:\n",
    "        print(\"{:20s}: {}\".format(item,parameters[item]))\n",
    "\n",
    "f_baryon=parameters['cosmology']['fBaryon']['Value']\n",
    "io_nRec=parameters['performance']['io_nRec']['Value']\n",
    "\n",
    "\n",
    "dtype_halo=np.dtype([\n",
    "    ('graph_ID',np.int32),\n",
    "    ('snap_ID',np.int32),\n",
    "    ('halo_ID',np.int32),\n",
    "    ('catalogID',np.int64),\n",
    "    ('mass',np.float32),\n",
    "    ('mass_baryon',np.float32),\n",
    "    ('mass_from_progenitors',np.float32)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Halo Properties class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HaloProperties:\n",
    "    \"\"\"A container for the properties needed for each halo.\n",
    "    \n",
    "    No sophisticated methods, just the constructor. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph_ID : str\n",
    "        The graph number in reference to the HDF group.\n",
    "    snap_ID : str\n",
    "        The snapshot number in reference to the HDF dataset.\n",
    "    halo_ID : str\n",
    "        The halo's ID number within the HDF dataset.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    graph_ID : str\n",
    "        The graph number in reference to the HDF group.\n",
    "    snap_ID : str\n",
    "        The snapshot number in reference to the HDF dataset.\n",
    "    halo_ID : str\n",
    "        The halo's ID number within the HDF dataset.\n",
    "    done : bool\n",
    "        Whether or not the halo has been processed.\n",
    "    catalog_ID : int\n",
    "        The ID of the halo corresponding to the original catalog, not just this file.\n",
    "    mass : int\n",
    "        Root mass of the halo taken from attributes of the graph.\n",
    "    mass_baryon : float\n",
    "        Mass of Baryons within the halo.\n",
    "    mass_from_progenitors : float \n",
    "        Total mass of all the progenitor halos.\n",
    "    mass_baryon_from_progenitors : float\n",
    "        Total mass of all the Baryons contained within the progenitor halos.\n",
    "    desc_start : int\n",
    "        The start index of the descendent halos for each halo.\n",
    "\n",
    "    \"\"\"   \n",
    "    def __init__(self,graph_ID,snap_ID,halo_ID):\n",
    "        \n",
    "        self.graph_ID=graph_ID\n",
    "        self.snap_ID=snap_ID\n",
    "        self.halo_ID=halo_ID\n",
    "        self.done=False\n",
    "        self.catalog_ID=-1\n",
    "        self.mass=0.\n",
    "        self.mass_baryon=0.\n",
    "        self.mass_from_progenitors=0.\n",
    "        self.mass_baryon_from_progenitors=0.\n",
    "        self.desc_start = 0\n",
    "        if parameters['modelSwitches']['HOD']: \n",
    "            self.mass_stars=0.\n",
    "            self.mass_stars_from_progenitors=0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High level driver routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_graph_input():\n",
    "    \"\"\"Opens input graph file using module level parameters.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    :obj:`File`\n",
    "        HDF5 file open in read mode\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    return h5.File(parameters['inputFiles']['graphFile'],'r')\n",
    "\n",
    "def open_galaxy_output():\n",
    "    \"\"\" Opens the output HDF5 file in write mode.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    :obj: 'File'\n",
    "        HDF5 file open in write mode.\n",
    "    \n",
    "    \"\"\"\n",
    "    return h5.File(parameters['outputFiles']['galaxyFile'],'w')\n",
    "\n",
    "def close_graph_io(open_HDF5_file):\n",
    "    \"\"\"Closes an open HDF5 file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    open_HDF5_file : :obj: 'File'\n",
    "        An open HDF5 file.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    graph_input_file.close()\n",
    "    return None\n",
    "\n",
    "def open_halo_output():\n",
    "    \"\"\" Open halo output file, create iobuffer, and output empty dataset.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    :obj: 'File'\n",
    "        An HDF5 file open in write mode.\n",
    "    ndarray\n",
    "        Empyy numpy array of varying type. See module level variables dtype_halo. \n",
    "    :obj: 'Dataset'\n",
    "        An HDF5 dataset.\n",
    "    int\n",
    "        Amount of halos that have been outputted. \n",
    "    \n",
    "    \"\"\"\n",
    "    halo_output_file = h5.File(parameters['outputFiles']['haloFile'],'w')\n",
    "    halo_output_data = np.empty(io_nRec,dtype=dtype_halo)\n",
    "    halo_output_dataset = halo_output_file.create_dataset('Halos',(0,),maxshape=(None,),\n",
    "                                                    dtype=dtype_halo,compression='gzip')\n",
    "    halo_output_iRec = 0\n",
    "    return halo_output_file,halo_output_data,halo_output_dataset,halo_output_iRec  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def output_halos(halo_output_file,halo_output_data,halo_output_dataset,halo_output_iRec):\n",
    "    \"\"\"Constructs a structured numpy array and calls flush_output module\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    halo_output_file : :obj: 'File'\n",
    "        An open HDF5 file for the data to be written to.\n",
    "    halo_output_data : ndarry\n",
    "        Structured numpy array to store halo attributes.\n",
    "    halo_output_dataset : :obj: 'Dataset'\n",
    "        HDF5 dataset to which the data should be stored.\n",
    "    halo_output_iRec: int\n",
    "        Amount of halos that have been outputted.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Amount of halos that have been outputted.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for halo in halos:\n",
    "        halo_output_data[halo_output_iRec]['graphID']=halo.graph_ID\n",
    "        halo_output_data[halo_output_iRec]['snapID']=halo.snap_ID\n",
    "        halo_output_data[halo_output_iRec]['haloID']=halo.halo_ID\n",
    "        halo_output_data[halo_output_iRec]['catalogID']=halo.catalog_ID\n",
    "        halo_output_data[halo_output_iRec]['mass']=halo.mass\n",
    "        halo_output_data[halo_output_iRec]['massBaryon']=halo.mass_baryon\n",
    "        halo_output_data[halo_output_iRec]['mass_fromProgenitors']=halo.mass_from_progenitors\n",
    "        halo_output_iRec+=1\n",
    "        if halo_output_iRec==io_nRec: halo_output_iRec=flush_output(halo_output_iRec,\n",
    "                                                                    halo_output_data,halo_output_dataset)\n",
    "            \n",
    "            \n",
    "    return halo_output_iRec\n",
    "\n",
    "    \n",
    "\n",
    "def flush_output(n_rec,output_data,output_dataset):\n",
    "    \"\"\"Writes data to an HDF5 dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_rec : int\n",
    "        Amount of halos that have been outputted.\n",
    "    output_data : ndarry\n",
    "        Structured numpy array containing halo properties.\n",
    "    ouput_dataset : :obj: 'Dataset'\n",
    "        HDF5 dataset in which the data should be stored.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Amount of halos that have been outputted\n",
    "        \n",
    "    \"\"\"\n",
    "    output_dataset.resize((output_dataset.shape[0]+n_rec,))\n",
    "    output_dataset[-n_rec:]=output_data[:n_rec]\n",
    "    n_rec=0\n",
    "    return n_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_halo(halo):\n",
    "    \"\"\"Small function that checks halo-properties before calling calculations.\n",
    "    \n",
    "    Controls what calculations are done. E.g. progenitors are not gathered\n",
    "    if halo is in the first generation. \n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    halo : :obj: 'Class'\n",
    "        HaloProperties class object\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Halo class object is updated\n",
    "        \n",
    "    \"\"\"\n",
    "    if verbosity>=3: print('Processing halo ',halo.halo_ID)\n",
    "    if halo.done==True: \n",
    "        print('Warning: processHalo: halo ',str(halo),' already processed.')\n",
    "        assert False\n",
    "    read_properties(halo)\n",
    "    calc_mass_to_desc(halo)\n",
    "    # Omit gatherProgenitors for first generation of halos!\n",
    "    if halo_properties_last_snap != None: gather_progenitors(halo)\n",
    "    set_baryon_fraction(halo)\n",
    "    # fixStellarFraction(halo) # Dummy routine.\n",
    "    halo.done=True\n",
    "    \n",
    "    return None\n",
    "    \n",
    "def read_properties(halo):\n",
    "    \"\"\"Reads the mass and descendent start index from HDF5 group attributes\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    halo : :obj: 'Class'\n",
    "        HaloProperties class object\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Halo class object is updated\n",
    "        \n",
    "    \"\"\"\n",
    "    # Reads halo properties from the input graph file\n",
    "    #halo.catalogID=graphInputFile[halo.graphID][halo.snapID][halo.haloID].attrs.get('halo_catalog_halo_ids')\n",
    "    halo.mass = graph_input_file[halo.graph_ID].attrs.get('root_mass') #halo_mass was here\n",
    "    halo.desc_start = graph_input_file[halo.graph_ID]['desc_start_index'][halo.halo_ID]\n",
    "    \n",
    "    return None\n",
    "\n",
    "def calc_mass_to_desc(halo):\n",
    "    \"\"\"Calculates the mass that does into each descendant in proportion to the desc_mass contribution\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    halo : :obj: 'Class'\n",
    "        HaloProperties class object\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Halo class object is updated\n",
    "        \n",
    "    \"\"\"\n",
    "    # Determines how much mass goes to each descendant, in proportion to desc_mass_contribution\n",
    "    desc_mass_contribution=graph_input_file[halo.graph_ID]['direct_desc_contribution'][halo.desc_start:]\n",
    "    desc_mass=np.array(desc_mass_contribution/np.sum(desc_mass_contribution)*halo.mass,dtype=np.float64)\n",
    "    halo.desc_mass=dict(zip(graph_input_file[halo.graph_ID]['direct_desc_ids'][halo.desc_start:],desc_mass))\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def set_baryon_fraction(halo):\n",
    "    \"\"\" Caclulates the mass of baryons in the halo\n",
    "    \n",
    "    Uses the global f_baryon (baryon fraction) variable to calculate the total\n",
    "    mass provided by baryons.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    halo : :obj: 'Class'\n",
    "        HaloProperties class object\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Halo class object is updated\n",
    "        \n",
    "    \"\"\"\n",
    "    halo.mass_baryon=f_baryon*max(halo.mass,halo.mass_from_progenitors)\n",
    "    return None\n",
    "    \n",
    "def gather_progenitors(halo):\n",
    "    \"\"\" Gathers the progenitors and calculates the mass from each one.\n",
    "    \n",
    "    I'm not entirely sure on the inner mechanics of this function. I will \n",
    "    probably re-write in trying to understand better.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    halo : :obj: 'Class'\n",
    "        HaloProperties class object\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Halo class object is updated\n",
    "    \n",
    "    \"\"\"\n",
    "    # Collects information about material inherited from progenitors\n",
    "    prog0_halo_ID=int(halo_properties_last_snap[0].halo_ID)\n",
    "    print(prog0_halo_ID)\n",
    "    for prog_halo_ID in graph_input_file[halo.graph_ID]['direct_prog_ids']:\n",
    "        \n",
    "        \n",
    "        # Position in progenitor (last_snap) halo list\n",
    "        if debug_flag and verbosity>=3 : print('direct_prog_ids =',prog_halo_ID)\n",
    "            \n",
    "    \n",
    "        \n",
    "        prog_index_last_snap=int(prog_halo_ID)-prog0_halo_ID\n",
    "        \n",
    "        #print(prog_haloID,halo.haloID,prog0_haloID,prog_index_lastSnap) \n",
    "        #print(halo.desc_mass)\n",
    "        if debug_flag and verbosity>=3: print('prog_index_last_snap =',prog_index_last_snap)\n",
    "        # Check halo association\n",
    "        # This is needed because HDF5 may store halos in a different order - \n",
    "        # if this happens, will need to add code to do a search over all halos\n",
    "        # in lastSnap, or to rearrange into ascending order.\n",
    "        if debug_flag:\n",
    "            print(halo_properties_last_snap[prog_index_last_snap].halo_ID)\n",
    "            print(prog_halo_ID)\n",
    "            assert int(halo_properties_last_snap[prog_index_last_snap].halo_ID) == int(prog_halo_ID)\n",
    "        # Now gather the appropriate information from the progenitor halo\n",
    "        halo.mass_from_progenitors+=halo_properties_last_snap[prog_index_last_snap].desc_mass[int(halo.halo_ID)]\n",
    "\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open graph input file\n",
    "# Note: can't pass undefined argument into function\n",
    "graphInputFile=openGraphInput()\n",
    "\n",
    "# Open output files\n",
    "# Note: can't pass undefined argument into function\n",
    "halo_output_file,halo_output_data,halo_output_dataset,halo_output_iRec  = openHaloOutput()\n",
    "# Note: no attempt here to include sub-halos (galaxies).  Let's get halos right first!\n",
    "#openGalaxyOutput(galaxyOutputFile)\n",
    "\n",
    "# Iteratively loop over halos, doing whatever processing is required.\n",
    "# This assumes that halos properties depend only upon those halos in their immediate past in the merger graph.\n",
    "\n",
    "# Loop over MergerGraphs.\n",
    "nHalo=0\n",
    "#nHaloGraph=0\n",
    "#nHaloSnap=0\n",
    "\n",
    "amount_of_graphs = len(graphInputFile['/nhalos_in_graph/'][:])\n",
    "\n",
    "for graphID in range(0,amount_of_graphs):\n",
    "    \n",
    "    if verbosity>=2: print('Processing graph',graphID)\n",
    "    graph=graphInputFile[str(graphID)]\n",
    "    haloProperties_lastSnap = None\n",
    "    snapID_old=-1\n",
    "    \n",
    "    for snapID in graph['snapshots']:\n",
    "        \n",
    "    \n",
    "        \n",
    "        if verbosity>=2: print('        snapshot',snapID)\n",
    "            \n",
    "        # Initialise halo properties\n",
    "        haloProperties_thisSnap = [haloProperties(str(graphID),snapID,haloID) for \n",
    "                                    haloID in graph['/{}/graph_halo_ids'.format(graphID)][:]]\n",
    "        \n",
    "        #print(vars(haloProperties_thisSnap[1]))\n",
    "        \n",
    "        print('Graph ID: {}, Snap ID: {}'.format(graphID,snapID))\n",
    "        for halo in haloProperties_thisSnap: \n",
    "            print('Halo ID: {}'.format(halo.haloID))\n",
    "            processHalo(halo)\n",
    "            nHalo +=1\n",
    "            if verbosity>=1 and nHalo%1000==0: print('Processed {:d} halos'.format(nHalo))\n",
    "        \n",
    "        \n",
    "        haloOutput_iRec=outputHalos(haloProperties_thisSnap,haloOutputData,haloOutputDataset,haloOutput_iRec)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        del haloProperties_lastSnap\n",
    "        #gc.collect() # garbage collection -- safe but very slow.\n",
    "        haloProperties_lastSnap = haloProperties_thisSnap\n",
    "        # Delete reference to this memory to free variable for new use.\n",
    "        del haloProperties_thisSnap\n",
    "        # Temporary halt to limit to finite time\n",
    "        if nHalo>=nHaloMax:\n",
    "            \n",
    "            if haloOutput_iRec>0: haloOutput_iRec=flushOutput(halo_output_iRec,halo_output_data,halo_output_dataset)\n",
    "\n",
    "            close_graph_io(haloOutputFile)\n",
    "            \n",
    "            assert False\n",
    "        \n",
    "\n",
    "\n",
    "if not debugFlag: del haloProperties_lastSnap\n",
    "\n",
    "# Close input file\n",
    "closeGraphInput(graphInputFile)\n",
    "\n",
    "# Close output files\n",
    "\n",
    "if haloOutput_iRec>0: haloOutput_iRec=flushOutput(halo_output_iRec,halo_output_data,halo_output_dataset)\n",
    "    \n",
    "close_graph_io(haloOutputFile)\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
